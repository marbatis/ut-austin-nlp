{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9941d50",
   "metadata": {},
   "source": [
    "# Bias in Word Embeddings\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/J_227g77Jqg](https://youtu.be/J_227g77Jqg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9204e1c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Examine how word embeddings capture societal biases present in training corpora.\n",
    "- Measure bias directions and discuss mitigation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4b34a",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- **Bias direction:** compute difference vectors (e.g., he - she) to probe stereotypes.\n",
    "- **WEAT:** Word Embedding Association Tests quantify associations statistically.\n",
    "- **Debiasing:** projection and neutralization can reduce measured bias but may hide underlying issues.\n",
    "- **Data reflection:** embedding bias mirrors imbalances in the underlying corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b5ff7",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Construct a simple embedding space and compute gender bias projections similar to the lecture (https://youtu.be/mYASY9b9Ec0), highlighting how associations emerge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b9010d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T01:27:55.596379Z",
     "iopub.status.busy": "2025-10-29T01:27:55.595966Z",
     "iopub.status.idle": "2025-10-29T01:27:55.667466Z",
     "shell.execute_reply": "2025-10-29T01:27:55.666551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender projection of doctor  : -0.000\n",
      "Gender projection of nurse   : -0.000\n",
      "Gender projection of engineer: -0.000\n",
      "Gender projection of artists : -0.000\n",
      "Gender projection of manager : 0.000\n",
      "Gender projection of teacher : 0.000\n",
      "\n",
      "After neutralizing along the gender direction:\n",
      "Gender projection of doctor  : -0.000\n",
      "Gender projection of nurse   : -0.000\n",
      "Gender projection of engineer: -0.000\n",
      "Gender projection of artists : -0.000\n",
      "Gender projection of manager : 0.000\n",
      "Gender projection of teacher : 0.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "corpus = [\n",
    "    'she is a skilled doctor and compassionate leader',\n",
    "    'he is a brilliant engineer and creative designer',\n",
    "    'the nurse offered patient support and kindness',\n",
    "    'the manager coordinated the project with precision',\n",
    "    'artists create inspiring work with emotion and style',\n",
    "    'scientists test hypotheses with rigorous experiments',\n",
    "    'teachers guide students with patience and care',\n",
    "    'the programmer solved complex problems quickly',\n",
    "    'she leads the team with empathy',\n",
    "    'he directs the team with authority'\n",
    "]\n",
    "\n",
    "vocab = sorted(set(' '.join(corpus).split()))\n",
    "word_to_id = {word: idx for idx, word in enumerate(vocab)}\n",
    "window = 2\n",
    "cooc = np.zeros((len(vocab), len(vocab)))\n",
    "for sentence in corpus:\n",
    "    words = sentence.split()\n",
    "    for i, word in enumerate(words):\n",
    "        for j in range(max(0, i - window), min(len(words), i + window + 1)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            cooc[word_to_id[word], word_to_id[words[j]]] += 1\n",
    "\n",
    "u, s, vt = np.linalg.svd(cooc)\n",
    "embeddings = u[:, :10] * np.sqrt(s[:10])\n",
    "\n",
    "he_vec = embeddings[word_to_id['he']]\n",
    "she_vec = embeddings[word_to_id['she']]\n",
    "gender_dir = he_vec - she_vec\n",
    "\n",
    "def projection(word):\n",
    "    idx = word_to_id.get(word)\n",
    "    if idx is None:\n",
    "        return 0.0\n",
    "    vec = embeddings[idx]\n",
    "    return (vec @ gender_dir) / (np.linalg.norm(gender_dir) + 1e-8)\n",
    "\n",
    "profession_words = ['doctor', 'nurse', 'engineer', 'artists', 'manager', 'teacher']\n",
    "for word in profession_words:\n",
    "    score = projection(word)\n",
    "    print(f\"Gender projection of {word:8s}: {score:.3f}\")\n",
    "\n",
    "print()\n",
    "print('After neutralizing along the gender direction:')\n",
    "for word in profession_words:\n",
    "    idx = word_to_id.get(word)\n",
    "    if idx is None:\n",
    "        print(f\"Gender projection of {word:8s}: 0.000\")\n",
    "        continue\n",
    "    vec = embeddings[idx]\n",
    "    bias_component = (vec @ gender_dir) / (np.linalg.norm(gender_dir) ** 2 + 1e-8) * gender_dir\n",
    "    neutral_vec = vec - bias_component\n",
    "    score = (neutral_vec @ gender_dir) / (np.linalg.norm(gender_dir) + 1e-8)\n",
    "    print(f\"Gender projection of {word:8s}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c54981",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc18813",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 14.5](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Distributed Representations of Words and Phrases and their Compositionality](https://papers.nips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf)\n",
    "- [A Scalable Hierarchical Distributed Language Model](https://papers.nips.cc/paper/2008/hash/1e056d2b0ebd5c878c550da6ac5d3724-Abstract.html)\n",
    "- [Neural Word Embedding as Implicit Matrix Factorization](https://papers.nips.cc/paper/2014/file/feab05aa91085b7a8012516bc3533958-Paper.pdf)\n",
    "- [GloVe: Global Vectors for Word Representation](https://www.aclweb.org/anthology/D14-1162/)\n",
    "- [Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606)\n",
    "- [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf)\n",
    "- [Black is to Criminal as Caucasian is to Police: Detecting and Removing Multiclass Bias in Word Embeddings](https://www.aclweb.org/anthology/N19-1062/)\n",
    "- [Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them](https://www.aclweb.org/anthology/N19-1061/)\n",
    "- [Deep Unordered Composition Rivals Syntactic Methods for Text Classification](https://www.aclweb.org/anthology/P15-1162/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d21d8e",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
