{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ebe2c9",
   "metadata": {},
   "source": [
    "# Zero-shot Prompting\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/YCq6b31Jb6E](https://youtu.be/YCq6b31Jb6E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea467e",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Use prompt wording alone to elicit useful behavior from pretrained language models without examples.\n",
    "- Explore how instructions, constraints, and formatting shape responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa009d4",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- **Instruction design:** clear cues about task, desired style, and constraints improve results.\n",
    "- **Role prompting:** setting model persona (e.g., 'You are a helpful assistant') changes tone.\n",
    "- **Guardrails:** zero-shot prompts can add safety checks and refusal conditions.\n",
    "- **Evaluation:** compare outputs to reference answers for calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71c3a6",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Implement a toy zero-shot prompting function that applies rule-based heuristics to show how prompt wording alone can trigger behaviors, echoing the lecture (https://youtu.be/tJtx14Qh6SU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4e716b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T01:32:50.732162Z",
     "iopub.status.busy": "2025-10-29T01:32:50.731801Z",
     "iopub.status.idle": "2025-10-29T01:32:50.742264Z",
     "shell.execute_reply": "2025-10-29T01:32:50.741849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Summarize: The meeting covered roadmap updates and hiring.\n",
      "Response: The meeting covered roadmap updates and hiring...\n",
      "\n",
      "Prompt: Classify the sentiment: I absolutely love this movie!\n",
      "Response: positive\n",
      "\n",
      "Prompt: Translate to French: \"dog\"\n",
      "Response: chien\n",
      "\n",
      "Prompt: Explain quantum physics.\n",
      "Response: I need more guidance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def zero_shot(prompt):\n",
    "    prompt_lower = prompt.lower()\n",
    "    if 'summarize' in prompt_lower:\n",
    "        text = prompt.split(':', 1)[-1].strip()\n",
    "        return text.split('.')[0].strip() + '...'\n",
    "    if 'sentiment' in prompt_lower:\n",
    "        if any(word in prompt_lower for word in ['love', 'great', 'excellent']):\n",
    "            return 'positive'\n",
    "        if any(word in prompt_lower for word in ['hate', 'awful', 'bad']):\n",
    "            return 'negative'\n",
    "        return 'neutral'\n",
    "    if 'translate' in prompt_lower and 'french' in prompt_lower:\n",
    "        dictionary = {'cat': 'chat', 'dog': 'chien', 'hello': 'bonjour'}\n",
    "        word = prompt_lower.split('\"')[-2]\n",
    "        return dictionary.get(word, '<unknown>')\n",
    "    return \"I need more guidance.\"\n",
    "\n",
    "examples = [\n",
    "    'Summarize: The meeting covered roadmap updates and hiring.',\n",
    "    'Classify the sentiment: I absolutely love this movie!',\n",
    "    'Translate to French: \"dog\"',\n",
    "    'Explain quantum physics.'\n",
    "]\n",
    "\n",
    "for prompt in examples:\n",
    "    print('Prompt:', prompt)\n",
    "    print('Response:', zero_shot(prompt))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013ddb0",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ace1d",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n",
    "- [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)\n",
    "- [Demystifying Prompts in Language Models via Perplexity Estimation](https://arxiv.org/abs/2212.04037)\n",
    "- [Calibrate Before Use: Improving Few-Shot Performance of Language Models](https://arxiv.org/abs/2102.09690)\n",
    "- [Holistic Evaluation of Language Models](https://arxiv.org/abs/2211.09110)\n",
    "- [Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?](https://arxiv.org/abs/2202.12837)\n",
    "- [In-context Learning and Induction Heads](https://arxiv.org/abs/2209.11895)\n",
    "- [Multitask Prompted Training Enables Zero-Shot Task Generalization](https://arxiv.org/abs/2110.08207)\n",
    "- [Scaling Instruction-Finetuned Language Models](https://arxiv.org/abs/2210.11416)\n",
    "- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n",
    "- [[Website] Stanford Alpaca: An Instruction-following LLaMA Model](https://crfm.stanford.edu/2023/03/13/alpaca.html)\n",
    "- [Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation](https://arxiv.org/abs/2212.07981)\n",
    "- [WiCE: Real-World Entailment for Claims in Wikipedia](https://arxiv.org/abs/2303.01432)\n",
    "- [SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization](https://arxiv.org/abs/2111.09525)\n",
    "- [FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation](https://arxiv.org/abs/2305.14251)\n",
    "- [RARR: Researching and Revising What Language Models Say, Using Language Models](https://arxiv.org/abs/2210.08726)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1085c9",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
