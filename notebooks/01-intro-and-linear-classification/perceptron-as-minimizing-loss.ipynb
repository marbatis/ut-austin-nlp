{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5a1afd",
   "metadata": {},
   "source": [
    "# Perceptron as Minimizing Loss\n",
    "\n",
    "- üì∫ **Video:** [https://youtu.be/hhTkyP7EzGw](https://youtu.be/hhTkyP7EzGw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95aae7b",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Offers a different perspective on the perceptron by framing it in terms of loss minimization. Instead of viewing the perceptron purely as an algorithm with update rules, this segment shows that it can be understood as minimizing a specific loss function (the ‚Äúperceptron loss‚Äù)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca282398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0d3ef",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- The lecture likely explains that each mistake the perceptron makes can be thought of as incurring some cost, and the perceptron update is reducing that cost.\n",
    "- By drawing parallels to gradient descent, the video connects perceptron updates to subgradient steps on a hinge-like loss (which is 0 if an example is correctly classified and linear if misclassified).\n",
    "- This not only demystifies why the perceptron works, but also sets the stage for logistic regression, which will use a different loss.\n",
    "- The key takeaway is that learning algorithms can be seen through the lens of optimization: even the perceptron is implicitly trying to minimize an objective (make as few mistakes as possible)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9132c2c",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f6240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny logistic regression demo on synthetic data\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(n_samples=800, n_features=10, random_state=0)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "clf = LogisticRegression(max_iter=500).fit(Xtr, ytr)\n",
    "print(\"Accuracy:\", accuracy_score(yte, clf.predict(Xte)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b579a8",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc85b3",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 2.0-2.5, 4.2-4.4.1](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Perceptron and logistic regression](https://www.cs.utexas.edu/~gdurrett/courses/online-course/perc-lr-connections.pdf)\n",
    "- [Eisenstein 4.1](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Perceptron and LR connections](https://www.cs.utexas.edu/~gdurrett/courses/online-course/perc-lr-connections.pdf)\n",
    "- [Thumbs up? Sentiment Classification using Machine Learning Techniques](https://www.aclweb.org/anthology/W02-1011/)\n",
    "- [Baselines and Bigrams: Simple, Good Sentiment and Topic Classification](https://www.aclweb.org/anthology/P12-2018/)\n",
    "- [Convolutional Neural Networks for Sentence Classification](https://www.aclweb.org/anthology/D14-1181/)\n",
    "- [[GitHub] NLP Progress on Sentiment Analysis](https://github.com/sebastianruder/NLP-progress/blob/master/english/sentiment_analysis.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81154283",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
