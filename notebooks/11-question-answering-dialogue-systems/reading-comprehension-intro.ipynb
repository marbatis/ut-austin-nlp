{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0548ba35",
   "metadata": {},
   "source": [
    "# Reading comprehension intro\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/gnUSE0fCbso](https://youtu.be/gnUSE0fCbso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ac138",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Introduces machine reading comprehension as answering questions about a passage, framing it as span extraction, multiple choice, or free-form generation. Key datasets (SQuAD, NewsQA, RACE) and task variants (extractive vs abstractive answers) are surveyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a84de",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- Baseline pipelinesâ€”tokenization, embedding, attention between question and passageâ€”set expectations for subsequent architectural deep dives.\n",
    "- Evaluation metrics like exact match and token-level F1 are explained along with their limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2cea0",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba919ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Try the exercises below and follow the linked materials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fd7b5",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f781906",
   "metadata": {},
   "source": [
    "## References\n",
    "- [MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text](https://www.aclweb.org/anthology/D13-1020.pdf)\n",
    "- [SQuAD: 100,000+ Questions for Machine Comprehension of Text](https://www.aclweb.org/anthology/D16-1264/)\n",
    "- [Adversarial Examples for Evaluating Reading Comprehension Systems](https://www.aclweb.org/anthology/D17-1215/)\n",
    "- [Reading Wikipedia to Answer Open-Domain Questions](https://arxiv.org/abs/1704.00051)\n",
    "- [Latent Retrieval for Weakly Supervised Open Domain Question Answering](https://www.aclweb.org/anthology/P19-1612.pdf)\n",
    "- [[Website] Natural Questions](https://ai.google.com/research/NaturalQuestions)\n",
    "- [retrieval-augmented generation](https://arxiv.org/pdf/2005.11401.pdf)\n",
    "- [WebGPT](https://arxiv.org/abs/2112.09332)\n",
    "- [HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering](https://arxiv.org/abs/1809.09600)\n",
    "- [Understanding Dataset Design Choices for Multi-hop Reasoning](https://www.aclweb.org/anthology/N19-1405/)\n",
    "- [Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering](https://openreview.net/forum?id=SJgVHkrYDH)\n",
    "- [QAMPARI](https://arxiv.org/abs/2205.12665)\n",
    "- [Wizards of Wikipedia: Knowledge-Powered Conversational Agents](https://arxiv.org/pdf/1811.01241.pdf)\n",
    "- [Task-Oriented Dialogue as Dataflow Synthesis](https://arxiv.org/abs/2009.11423)\n",
    "- [A Neural Network Approach to Context-Sensitive Generation of Conversational Responses](https://arxiv.org/abs/1506.06714)\n",
    "- [A Diversity-Promoting Objective Function for Neural Conversation Models](https://arxiv.org/abs/1510.03055)\n",
    "- [Recipes for building an open-domain chatbot](https://arxiv.org/pdf/2004.13637.pdf)\n",
    "- [Kurt Shuster et al.](https://arxiv.org/abs/2208.03188)\n",
    "- [character.ai](https://character.ai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ae4cb",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
