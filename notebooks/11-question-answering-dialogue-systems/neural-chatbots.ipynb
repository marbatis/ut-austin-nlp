{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731b16fd",
   "metadata": {},
   "source": [
    "# Neural Chatbots\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/Hc7P3QukmJk](https://youtu.be/Hc7P3QukmJk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61952afe",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Use neural sequence models to generate conversational responses.\n",
    "- Learn about encoder-decoder architectures and beam search decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02203ef1",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- **Seq2seq training:** maximize likelihood of target response given context.\n",
    "- **Teacher forcing:** stabilize training but can cause exposure bias.\n",
    "- **Decoding:** sampling, beam search, or nucleus sampling control diversity.\n",
    "- **Conditioning:** persona or style tokens steer outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb6ba7",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Train a miniature seq2seq chatbot on tiny pairs to echo the lecture (https://youtu.be/kohvfY7l8Ww) with quick experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b705bbfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T01:33:33.610299Z",
     "iopub.status.busy": "2025-10-29T01:33:33.609985Z",
     "iopub.status.idle": "2025-10-29T01:33:35.598207Z",
     "shell.execute_reply": "2025-10-29T01:33:35.597895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  50 | loss 0.3282\n",
      "epoch 100 | loss 0.0410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150 | loss 0.0167\n",
      "epoch 200 | loss 0.0100\n",
      "Generated response: hello there!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "pairs = [\n",
    "    ('hi', 'hello there!'),\n",
    "    ('how are you?', 'i am doing well!'),\n",
    "    ('thanks', 'you are welcome!')\n",
    "]\n",
    "\n",
    "vocab = sorted(set(' '.join(u + ' ' + v for u, v in pairs))) + ['<pad>', '<s>', '</s>']\n",
    "char_to_id = {c: i for i, c in enumerate(vocab)}\n",
    "\n",
    "max_len = 20\n",
    "\n",
    "def encode(text):\n",
    "    ids = [char_to_id['<s>']] + [char_to_id[c] for c in text] + [char_to_id['</s>']]\n",
    "    ids += [char_to_id['<pad>']] * (max_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "src = torch.tensor([encode(u) for u, _ in pairs])\n",
    "tgt = torch.tensor([encode(v) for _, v in pairs])\n",
    "\n",
    "embed = nn.Embedding(len(vocab), 32)\n",
    "encoder = nn.GRU(32, 32, batch_first=True)\n",
    "decoder = nn.GRU(32, 32, batch_first=True)\n",
    "out = nn.Linear(32, len(vocab))\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])\n",
    "optimizer = torch.optim.Adam(list(embed.parameters()) + list(encoder.parameters()) + list(decoder.parameters()) + list(out.parameters()), lr=5e-3)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    enc_in = embed(src)\n",
    "    _, hidden = encoder(enc_in)\n",
    "    dec_in = embed(tgt[:, :-1])\n",
    "    outputs, _ = decoder(dec_in, hidden)\n",
    "    logits = out(outputs)\n",
    "    loss = criterion(logits.reshape(-1, len(vocab)), tgt[:, 1:].reshape(-1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"epoch {epoch:3d} | loss {loss.item():.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    prompt = torch.tensor([encode('hi')])\n",
    "    enc_in = embed(prompt)\n",
    "    _, hidden = encoder(enc_in)\n",
    "    dec_input = torch.tensor([[char_to_id['<s>']]])\n",
    "    response = []\n",
    "    hidden_state = hidden\n",
    "    for _ in range(max_len):\n",
    "        emb_in = embed(dec_input)\n",
    "        output, hidden_state = decoder(emb_in, hidden_state)\n",
    "        logits = out(output.squeeze(1))\n",
    "        next_id = logits.argmax(dim=-1)\n",
    "        token = next_id.item()\n",
    "        if token == char_to_id['</s>']:\n",
    "            break\n",
    "        if token != char_to_id['<pad>']:\n",
    "            response.append(vocab[token])\n",
    "        dec_input = next_id.unsqueeze(1)\n",
    "    print('Generated response:', ''.join(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696fa7e2",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344edff8",
   "metadata": {},
   "source": [
    "## References\n",
    "- [MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text](https://www.aclweb.org/anthology/D13-1020.pdf)\n",
    "- [SQuAD: 100,000+ Questions for Machine Comprehension of Text](https://www.aclweb.org/anthology/D16-1264/)\n",
    "- [Adversarial Examples for Evaluating Reading Comprehension Systems](https://www.aclweb.org/anthology/D17-1215/)\n",
    "- [Reading Wikipedia to Answer Open-Domain Questions](https://arxiv.org/abs/1704.00051)\n",
    "- [Latent Retrieval for Weakly Supervised Open Domain Question Answering](https://www.aclweb.org/anthology/P19-1612.pdf)\n",
    "- [[Website] Natural Questions](https://ai.google.com/research/NaturalQuestions)\n",
    "- [retrieval-augmented generation](https://arxiv.org/pdf/2005.11401.pdf)\n",
    "- [WebGPT](https://arxiv.org/abs/2112.09332)\n",
    "- [HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering](https://arxiv.org/abs/1809.09600)\n",
    "- [Understanding Dataset Design Choices for Multi-hop Reasoning](https://www.aclweb.org/anthology/N19-1405/)\n",
    "- [Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering](https://openreview.net/forum?id=SJgVHkrYDH)\n",
    "- [QAMPARI](https://arxiv.org/abs/2205.12665)\n",
    "- [Wizards of Wikipedia: Knowledge-Powered Conversational Agents](https://arxiv.org/pdf/1811.01241.pdf)\n",
    "- [Task-Oriented Dialogue as Dataflow Synthesis](https://arxiv.org/abs/2009.11423)\n",
    "- [A Neural Network Approach to Context-Sensitive Generation of Conversational Responses](https://arxiv.org/abs/1506.06714)\n",
    "- [A Diversity-Promoting Objective Function for Neural Conversation Models](https://arxiv.org/abs/1510.03055)\n",
    "- [Recipes for building an open-domain chatbot](https://arxiv.org/pdf/2004.13637.pdf)\n",
    "- [Kurt Shuster et al.](https://arxiv.org/abs/2208.03188)\n",
    "- [character.ai](https://character.ai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77fd07",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
