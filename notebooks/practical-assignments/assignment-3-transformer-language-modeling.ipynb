{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d428d9d",
   "metadata": {},
   "source": [
    "# Assignment 3: Transformer Language Modeling\n",
    "\n",
    "- [Prompt](https://www.cs.utexas.edu/~gdurrett/courses/online-course/a3.pdf)\n",
    "- [Starter code + data](https://www.cs.utexas.edu/~gdurrett/courses/online-course/a3-distrib.tgz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954bca1",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Build and experiment with a Transformer-based language model. The goal is to implement multi-head self-attention, positional encodings, and decoding to generate fluent text, reinforcing Week 5 material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5984c3",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- Implement scaled dot-product attention, multi-head attention, and feed-forward blocks for an autoregressive LM.\n",
    "- Train the model on the provided corpus; track perplexity and sample generations across checkpoints.\n",
    "- Study the effect of architecture/optimisation choices (layers, heads, learning rate schedules).\n",
    "- Analyse generated text for coherence and discuss strengths/limitations compared to n-gram baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970bc7b5",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "- Clone/update the assignment starter repository.\n",
    "- Set up the recommended environment (see prompt).\n",
    "- Fill in TODO blocks incrementally, keeping a training log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d4737",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "- Transformer LM training code with reproducible configuration.\n",
    "- Evaluation summary (perplexity, qualitative samples, ablation insights).\n",
    "- Reflection linking results to Week 5 lectures on attention and decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ff997",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- What worked well?\n",
    "- What failed or surprised you?\n",
    "- How does this assignment connect to lecture material?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this space for quick experiments or sanity checks\n",
    "import random\n",
    "random.seed(0)\n",
    "print('Ready to prototype!')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
