{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17268537",
   "metadata": {},
   "source": [
    "# Nucleus Sampling\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/JETxaSaj6_k](https://youtu.be/JETxaSaj6_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688fc7d",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Sample from a language model by restricting to the smallest probability mass whose sum exceeds threshold p.\n",
    "- Balance diversity and quality better than top-k sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61738d",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- **Top-p set:** adaptively choose the candidate set per time step.\n",
    "- **Calibration:** lower p favors high-confidence tokens; higher p increases diversity.\n",
    "- **Temperature:** rescale logits before sampling to smooth or sharpen distributions.\n",
    "- **Practicality:** widely used in modern LMs to avoid degenerate outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f9da8",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Implement nucleus sampling on a contrived logit distribution and draw samples to match the lecture (https://youtu.be/YclONl1EW7E) intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41133cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T01:29:16.175675Z",
     "iopub.status.busy": "2025-10-29T01:29:16.175337Z",
     "iopub.status.idle": "2025-10-29T01:29:16.242834Z",
     "shell.execute_reply": "2025-10-29T01:29:16.242301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nucleus (top-p) tokens: ['cat', 'dog', 'bird', 'fish']\n",
      "Sampled sequence: ['cat', 'cat', 'cat', 'cat', 'dog']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab = ['cat', 'dog', 'bird', 'fish', 'lizard', 'hamster']\n",
    "logits = np.array([2.4, 1.8, 0.5, 0.2, -0.3, -1.0])\n",
    "\n",
    "p = 0.9\n",
    "probs = np.exp(logits - logits.max())\n",
    "probs /= probs.sum()\n",
    "sorted_indices = np.argsort(probs)[::-1]\n",
    "cumulative = np.cumsum(probs[sorted_indices])\n",
    "threshold_idx = np.searchsorted(cumulative, p) + 1\n",
    "nucleus_indices = sorted_indices[:threshold_idx]\n",
    "\n",
    "nucleus_probs = probs[nucleus_indices]\n",
    "nucleus_probs /= nucleus_probs.sum()\n",
    "\n",
    "samples = np.random.choice([vocab[i] for i in nucleus_indices], size=5, p=nucleus_probs)\n",
    "print('Nucleus (top-p) tokens:', [vocab[i] for i in nucleus_indices])\n",
    "print('Sampled sequence:', samples.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9da2e3",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c1b3d",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)\n",
    "- [Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732)\n",
    "- [Rethinking Attention with Performers](https://arxiv.org/abs/2009.14794)\n",
    "- [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150)\n",
    "- [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d974af9",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
