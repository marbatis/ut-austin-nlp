{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c091f1",
   "metadata": {},
   "source": [
    "# Chain-of-thought: Extensions and Analysis\n",
    "\n",
    "- üì∫ **Video:** [https://youtu.be/9sFyzMywKmo](https://youtu.be/9sFyzMywKmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3a341",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Continues on CoT by mentioning follow-up improvements and investigations It likely covers:  ‚ó¶ Ye et al. 2023 (Complementary explanations for ICL) - possibly about combining different rationales or ensuring consistency for better results in few-shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df660fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7b8c4",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- ‚ó¶ Possibly ‚ÄúSelf-consistency‚Äù decoding (Wang et al.\n",
    "- 2022) approach: instead of one chain, sample multiple CoT chains and take majority answer - which was shown to boost accuracy ( because it reduces variability) - though that specific reference not listed, might be implicitly known.\n",
    "- ‚ó¶ PAL (Gao et al.\n",
    "- 2022) Program-Aided Language models - idea of generating Python code as the chain-of-thought for math problems rather than natural language - which often improves accuracy as code execution can verify and han precise calc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a00683",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Try the exercises below and follow the linked materials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e190f",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521913d9",
   "metadata": {},
   "source": [
    "## References\n",
    "- [The Mythos of Model Interpretability](https://arxiv.org/pdf/1606.03490.pdf)\n",
    "- [Deep Unordered Composition Rivals Syntactic Methods for Text Classification](https://www.aclweb.org/anthology/P15-1162/)\n",
    "- [Analysis Methods in Neural Language Processing: A Survey](https://arxiv.org/pdf/1812.08951.pdf)\n",
    "- [\"Why Should I Trust You?\" Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938.pdf)\n",
    "- [Axiomatic Attribution for Deep Networks](https://arxiv.org/pdf/1703.01365.pdf)\n",
    "- [BERT Rediscovers the Classical NLP Pipeline](https://arxiv.org/pdf/1905.05950.pdf)\n",
    "- [What Do You Learn From Context? Probing For Sentence Structure In Contextualized Word Represenations](https://arxiv.org/pdf/1905.06316.pdf)\n",
    "- [Annotation Artifacts in Natural Language Inference Data](https://www.aclweb.org/anthology/N18-2017/)\n",
    "- [Hypothesis Only Baselines in Natural Language Inference](https://www.aclweb.org/anthology/S18-2023/)\n",
    "- [Did the Model Understand the Question?](https://www.aclweb.org/anthology/P18-1176/)\n",
    "- [Swag: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference](https://www.aclweb.org/anthology/D18-1009.pdf)\n",
    "- [Generating Visual Explanations](https://arxiv.org/pdf/1603.08507.pdf)\n",
    "- [e-SNLI: Natural Language Inference with Natural Language Explanations](https://arxiv.org/abs/1812.01193)\n",
    "- [Explaining Question Answering Models through Text Generation](https://arxiv.org/pdf/2004.05569.pdf)\n",
    "- [Program Induction by Rationale Generation : Learning to Solve and Explain Algebraic Word Problems](https://arxiv.org/abs/1705.04146)\n",
    "- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)\n",
    "- [The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning](https://arxiv.org/abs/2205.03401)\n",
    "- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)\n",
    "- [Complementary Explanations for Effective In-Context Learning](https://arxiv.org/pdf/2211.13892.pdf)\n",
    "- [PAL: Program-aided Language Models](https://arxiv.org/abs/2211.10435)\n",
    "- [Measuring and Narrowing the Compositionality Gap in Language Models](https://arxiv.org/abs/2210.03350)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef3e42f",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
