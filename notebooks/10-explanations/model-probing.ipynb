{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07c023d",
   "metadata": {},
   "source": [
    "# Model Probing\n",
    "\n",
    "- üì∫ **Video:** [https://youtu.be/a6u6WM5wcLQ](https://youtu.be/a6u6WM5wcLQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca0094",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Now shifts to analyzing what linguistic information is encoded in model representations (internal vectors) via probing tasks It explains that one approach to interpret models is to take the hidden states (like BERT's word embeddings from various layers) and train simple classifiers to predict linguistic properties (e.g., POS tag, syntactic chunk, dependency relation, semantic role, etc.) from those states. If the classifier can predict well, it implies the model's representation contains that info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f57635e",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- The video references Tenney et al.\n",
    "- 2019 ‚ÄúBERT rediscovers the classical NLP pipeline‚Äù which found that BERT's layers progressively encode syntax then semantic info, akin to old pipeline stages - e.g., earlier layers encode POS and phrase chunking, mid layers dependencies, later layers coreference or semanti It likely visualizes that result: tasks like POS, parsing, NER can be extracted at different depths of BERT, showing an ordering.\n",
    "- Also references Tenney's other 2019 work on probing context (‚ÄúWhat do you learn from context?‚Äù) exploring how sentence structure info is encoded.\n",
    "- The video might discuss Structural Probe (Hewitt & Manning 2019) that found a linear transformation of BERT's space where distances correlate with parse tree distances - implying BERT implicitly learned a syntactic tree geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6a17f",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Try the exercises below and follow the linked materials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5bcbe",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6d358",
   "metadata": {},
   "source": [
    "## References\n",
    "- [The Mythos of Model Interpretability](https://arxiv.org/pdf/1606.03490.pdf)\n",
    "- [Deep Unordered Composition Rivals Syntactic Methods for Text Classification](https://www.aclweb.org/anthology/P15-1162/)\n",
    "- [Analysis Methods in Neural Language Processing: A Survey](https://arxiv.org/pdf/1812.08951.pdf)\n",
    "- [\"Why Should I Trust You?\" Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938.pdf)\n",
    "- [Axiomatic Attribution for Deep Networks](https://arxiv.org/pdf/1703.01365.pdf)\n",
    "- [BERT Rediscovers the Classical NLP Pipeline](https://arxiv.org/pdf/1905.05950.pdf)\n",
    "- [What Do You Learn From Context? Probing For Sentence Structure In Contextualized Word Represenations](https://arxiv.org/pdf/1905.06316.pdf)\n",
    "- [Annotation Artifacts in Natural Language Inference Data](https://www.aclweb.org/anthology/N18-2017/)\n",
    "- [Hypothesis Only Baselines in Natural Language Inference](https://www.aclweb.org/anthology/S18-2023/)\n",
    "- [Did the Model Understand the Question?](https://www.aclweb.org/anthology/P18-1176/)\n",
    "- [Swag: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference](https://www.aclweb.org/anthology/D18-1009.pdf)\n",
    "- [Generating Visual Explanations](https://arxiv.org/pdf/1603.08507.pdf)\n",
    "- [e-SNLI: Natural Language Inference with Natural Language Explanations](https://arxiv.org/abs/1812.01193)\n",
    "- [Explaining Question Answering Models through Text Generation](https://arxiv.org/pdf/2004.05569.pdf)\n",
    "- [Program Induction by Rationale Generation : Learning to Solve and Explain Algebraic Word Problems](https://arxiv.org/abs/1705.04146)\n",
    "- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)\n",
    "- [The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning](https://arxiv.org/abs/2205.03401)\n",
    "- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)\n",
    "- [Complementary Explanations for Effective In-Context Learning](https://arxiv.org/pdf/2211.13892.pdf)\n",
    "- [PAL: Program-aided Language Models](https://arxiv.org/abs/2211.10435)\n",
    "- [Measuring and Narrowing the Compositionality Gap in Language Models](https://arxiv.org/abs/2210.03350)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297d453",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
