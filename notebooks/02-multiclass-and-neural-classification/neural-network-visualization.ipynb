{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a81aed",
   "metadata": {},
   "source": [
    "# Neural Network Visualization\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/rdohzaGa8aE](https://youtu.be/rdohzaGa8aE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe18cd6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Provides an intuitive visualization of how neural networks learn, likely drawing on Chris Olah's famous blog post on neural nets and topology In this segment, the instructor probably uses low-dimensional examples (like points in a 2D plane colored by class) to show what a neural network is doing internally. For a very simple network (one hidden layer of a few neurons), one can actually plot how the input space is transformed by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665fa46c",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- The video might show a sequence of images: initially, the data isn't linearly separable; after the first layer's transformation, the data points in the new space are warped closer to being linearly separable; after the second layer, they are separated by a hyperplane.\n",
    "- This aligns with the idea from Olah's blog: each layer of a neural network learns a representation of the data that is more linearly separable than the last For instance, the video might visualize two intertwined spirals (a classic toy problem): a neural network can gradually untangle these spirals layer by layer, as seen by plotting the intermediate activations.\n",
    "- Such visuals give a strong intuition that each hidden layer applies a nonlinear transformation (stretching/squishing the space) to bring the classes into a form that a simple separator (line) can split The video may also highlight that while we can visualize this for 2D, in NLP our feature space is huge (vocabularies of thousands) and hidden layers might be high-dimensional - so we can't directly see it, but the principle holds.\n",
    "- By the end, students should develop an intuition that neural networks are not black magic - they are systematically remolding the feature space to make the job easier for the final linear classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc403164",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Try the exercises below and follow the linked materials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f860313",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b499c",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 4.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Multiclass lecture note](https://www.cs.utexas.edu/~gdurrett/courses/online-course/multiclass.pdf)\n",
    "- [A large annotated corpus for learning natural language inference](https://www.aclweb.org/anthology/D15-1075/)\n",
    "- [Authorship Attribution of Micro-Messages](https://www.aclweb.org/anthology/D13-1193/)\n",
    "- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n",
    "- [[Article] Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)\n",
    "- [[Blog] Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "- [Eisenstein Chapter 3.1-3.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Dropout: a simple way to prevent neural networks from overfitting](https://dl.acm.org/doi/10.5555/2627435.2670313)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
    "- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://papers.nips.cc/paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14a8fb",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
