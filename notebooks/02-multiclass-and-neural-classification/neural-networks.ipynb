{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e79a010",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/DU_p-RBy5gM](https://youtu.be/DU_p-RBy5gM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bc906",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Marks the beginning of the course's deep learning journey by introducing neural networks for NLP. This video likely starts with the basic intuition: a neural network is a series of linear transformations interwoven with non-linear activation functions, allowing models to fit much more complex relationships than a single linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c2a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193a0f5",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- It might use a simple example - classifying data points in 2D that are not linearly separable - and show that a network with a hidden layer can carve out non-linear decision boundaries to separate them (something a linear model cannot do).\n",
    "- The video explains key concepts: neurons (units computing weighted sums), layers (input layer of features, hidden layer(s) that transform inputs, output layer giving final scores), and activation functions like ReLU or tanh that introduce non-linearity.\n",
    "- It emphasizes that with at least one hidden layer, neural nets can learn more abstract features of the input.\n",
    "- In NLP terms, instead of manually creating n-gram features, a neural network can learn its own feature representation from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51105f67",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Try the exercises below and follow the linked materials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca224792",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833c20b",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 4.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Multiclass lecture note](https://www.cs.utexas.edu/~gdurrett/courses/online-course/multiclass.pdf)\n",
    "- [A large annotated corpus for learning natural language inference](https://www.aclweb.org/anthology/D15-1075/)\n",
    "- [Authorship Attribution of Micro-Messages](https://www.aclweb.org/anthology/D13-1193/)\n",
    "- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n",
    "- [[Article] Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)\n",
    "- [[Blog] Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "- [Eisenstein Chapter 3.1-3.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Dropout: a simple way to prevent neural networks from overfitting](https://dl.acm.org/doi/10.5555/2627435.2670313)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
    "- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://papers.nips.cc/paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb399ca",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
