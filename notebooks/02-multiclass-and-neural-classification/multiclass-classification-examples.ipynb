{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a7bf1e",
   "metadata": {},
   "source": [
    "# Multiclass Classification Examples\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/va2i7LXt9zI](https://youtu.be/va2i7LXt9zI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c91a26",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Survey real-world multiclass NLP setups such as intent detection or topic tagging.\n",
    "- Understand evaluation beyond accuracy, including per-class precision/recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd7362c",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- **Label sets:** multiclass tasks assume one gold label drawn from several mutually exclusive options.\n",
    "- **One-vs-rest vs. multinomial:** training strategies differ in how they share parameters across classes.\n",
    "- **Class imbalance:** rare classes demand macro-averaged metrics.\n",
    "- **Error inspection:** confusion matrices highlight where labels are confusable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c22db",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Generate a synthetic 4-class dataset, train a multinomial logistic regression model, and inspect per-class metrics to connect to the lecture (https://youtu.be/JUdxV9C0VGA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f9f0bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T01:26:10.194601Z",
     "iopub.status.busy": "2025-10-29T01:26:10.194106Z",
     "iopub.status.idle": "2025-10-29T01:26:11.010645Z",
     "shell.execute_reply": "2025-10-29T01:26:11.010377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.771     0.873     0.819       197\n",
      "           1      0.728     0.776     0.752       152\n",
      "           2      0.690     0.588     0.635       102\n",
      "           3      0.679     0.388     0.494        49\n",
      "\n",
      "    accuracy                          0.738       500\n",
      "   macro avg      0.717     0.656     0.675       500\n",
      "weighted avg      0.733     0.738     0.729       500\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "     0    1   2   3\n",
      "0  172   10  13   2\n",
      "1   17  118  14   3\n",
      "2   21   17  60   4\n",
      "3   13   17   0  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcelosilveira/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=500, n_features=6, n_classes=4, n_informative=6, n_redundant=0,\n",
    "    class_sep=1.5, weights=[0.4, 0.3, 0.2, 0.1], random_state=4\n",
    ")\n",
    "model = LogisticRegression(max_iter=2000, multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X, y)\n",
    "\n",
    "preds = model.predict(X)\n",
    "print(classification_report(y, preds, digits=3))\n",
    "print()\n",
    "print('Confusion matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y, preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a071dd66",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5a417",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 4.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Multiclass lecture note](https://www.cs.utexas.edu/~gdurrett/courses/online-course/multiclass.pdf)\n",
    "- [A large annotated corpus for learning natural language inference](https://www.aclweb.org/anthology/D15-1075/)\n",
    "- [Authorship Attribution of Micro-Messages](https://www.aclweb.org/anthology/D13-1193/)\n",
    "- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n",
    "- [[Article] Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)\n",
    "- [[Blog] Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "- [Eisenstein Chapter 3.1-3.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Dropout: a simple way to prevent neural networks from overfitting](https://dl.acm.org/doi/10.5555/2627435.2670313)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
    "- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://papers.nips.cc/paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc83d6",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
