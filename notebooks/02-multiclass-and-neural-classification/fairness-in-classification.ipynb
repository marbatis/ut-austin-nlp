{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1374d48",
   "metadata": {},
   "source": [
    "# Fairness in Classification\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/N4f2-S19LME](https://youtu.be/N4f2-S19LME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f66db77",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Quantify how traditional accuracy metrics can obscure disparities across demographic groups.\n",
    "- Explore mitigation levers such as reweighting decisions after training a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f943073",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- **Group fairness metrics:** compare positive prediction rates, true positive rates, and false positive rates between groups.\n",
    "- **Bias amplification:** data imbalance or label bias can cause models to widen gaps seen in the training set.\n",
    "- **Post-processing:** calibration or threshold adjustment can partially correct disparities without retraining.\n",
    "- **Trade-offs:** improving one fairness criterion can harm others, so context-sensitive choices are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f4855",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Train logistic regression on a synthetic dataset with a sensitive attribute, then measure accuracy, demographic parity, and equal opportunity gaps as discussed in the lecture (https://youtu.be/N4f2-S19LME)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60bc4ba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T01:26:07.089698Z",
     "iopub.status.busy": "2025-10-29T01:26:07.089413Z",
     "iopub.status.idle": "2025-10-29T01:26:07.895549Z",
     "shell.execute_reply": "2025-10-29T01:26:07.895277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.977     0.977       307\n",
      "           1      0.976     0.976     0.976       293\n",
      "\n",
      "    accuracy                          0.977       600\n",
      "   macro avg      0.977     0.977     0.977       600\n",
      "weighted avg      0.977     0.977     0.977       600\n",
      "\n",
      "\n",
      "Group metrics:\n",
      "Group 0: positive_rate=0.470 | TPR=0.950 | FPR=0.000\n",
      "Group 1: positive_rate=0.505 | TPR=1.000 | FPR=0.043\n",
      "\n",
      "Demographic parity gap: 0.03476719688778407\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rng = np.random.default_rng(12)\n",
    "num_samples = 600\n",
    "group = rng.integers(0, 2, size=num_samples)\n",
    "feature1 = rng.normal(loc=group * 0.8, scale=1.0, size=num_samples)\n",
    "feature2 = rng.normal(size=num_samples)\n",
    "linear = 0.6 * feature1 + 0.3 * feature2 - 0.5 * group\n",
    "probs = 1 / (1 + np.exp(-linear))\n",
    "y = (probs > 0.5).astype(int)\n",
    "\n",
    "X = np.column_stack([feature1, feature2, group])\n",
    "clf = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "clf.fit(X, y)\n",
    "\n",
    "preds = clf.predict(X)\n",
    "print(classification_report(y, preds, digits=3))\n",
    "\n",
    "def group_stats(name, mask):\n",
    "    g_truth = y[mask]\n",
    "    g_pred = preds[mask]\n",
    "    positive_rate = g_pred.mean()\n",
    "    true_positive = ((g_pred == 1) & (g_truth == 1)).sum()\n",
    "    positives = (g_truth == 1).sum()\n",
    "    tpr = true_positive / positives if positives else 0.0\n",
    "    false_positive = ((g_pred == 1) & (g_truth == 0)).sum()\n",
    "    negatives = (g_truth == 0).sum()\n",
    "    fpr = false_positive / negatives if negatives else 0.0\n",
    "    print(f\"{name}: positive_rate={positive_rate:.3f} | TPR={tpr:.3f} | FPR={fpr:.3f}\")\n",
    "\n",
    "print()\n",
    "print('Group metrics:')\n",
    "for g in [0, 1]:\n",
    "    group_stats(f\"Group {g}\", group == g)\n",
    "print()\n",
    "print('Demographic parity gap:', abs(preds[group==0].mean() - preds[group==1].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f950908f",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e986c8",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 4.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Multiclass lecture note](https://www.cs.utexas.edu/~gdurrett/courses/online-course/multiclass.pdf)\n",
    "- [A large annotated corpus for learning natural language inference](https://www.aclweb.org/anthology/D15-1075/)\n",
    "- [Authorship Attribution of Micro-Messages](https://www.aclweb.org/anthology/D13-1193/)\n",
    "- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n",
    "- [[Article] Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)\n",
    "- [[Blog] Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "- [Eisenstein Chapter 3.1-3.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Dropout: a simple way to prevent neural networks from overfitting](https://dl.acm.org/doi/10.5555/2627435.2670313)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
    "- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://papers.nips.cc/paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea4921",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
