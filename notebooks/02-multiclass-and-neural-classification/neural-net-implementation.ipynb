{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "477d7a8b",
   "metadata": {},
   "source": [
    "# Neural Net Implementation\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/IRZCQO18QAI](https://youtu.be/IRZCQO18QAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c264cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Likely a more practical session that walks through how one would implement a simple neural network classifier. The instructor might show pseudocode or actual code structure: for example, a class for a NeuralNetwork with methods forward(x) and backward(x, grad) to illustrate modular design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093e54a",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- They could demonstrate using a library like NumPy/PyTorch to create and train a small network on a toy dataset.\n",
    "- The video might cover details like how to initialize weights (random initialization, because starting all weights at zero wouldn't work), and how to loop through training data, accumulate gradients, and update weights.\n",
    "- If coded live or shown in a notebook, it would give students an idea of the effort involved compared to linear models.\n",
    "- This is also an opportunity to highlight debugging tips - e.g., checking dimensions of weight matrices, making sure activation outputs make sense, and monitoring the loss decrease during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b3b5b",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fdccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Try the exercises below and follow the linked materials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26e297",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16acdb91",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 4.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Multiclass lecture note](https://www.cs.utexas.edu/~gdurrett/courses/online-course/multiclass.pdf)\n",
    "- [A large annotated corpus for learning natural language inference](https://www.aclweb.org/anthology/D15-1075/)\n",
    "- [Authorship Attribution of Micro-Messages](https://www.aclweb.org/anthology/D13-1193/)\n",
    "- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n",
    "- [[Article] Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)\n",
    "- [[Blog] Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "- [Eisenstein Chapter 3.1-3.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Dropout: a simple way to prevent neural networks from overfitting](https://dl.acm.org/doi/10.5555/2627435.2670313)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
    "- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://papers.nips.cc/paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9f82c1",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
