{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0542ff",
   "metadata": {},
   "source": [
    "# Multiclass Perceptron and Logistic Regression\n",
    "\n",
    "- üì∫ **Video:** [https://youtu.be/EA627DC7k6M](https://youtu.be/EA627DC7k6M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0258992",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Focuses on the algorithms and training procedures for multiclass classifiers. Building on the introduction, this video likely demonstrates how the perceptron algorithm works with multiple classes (e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4080b472",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- if the predicted class is wrong, update the weights for the true class and the predicted class accordingly).\n",
    "- For logistic regression, it would outline how to compute gradients for each weight vector with respect to the cross-entropy loss.\n",
    "- The video might include pseudocode or equations for these updates.\n",
    "- It could also show a quick example of a training iteration on a multiclass problem: say we have a hea labeled ‚ÄúSPORTS‚Äù but the model predicted ‚ÄúHEALTH‚Äù; the perceptron update would add the feature vector to w_SPORTS and subtract it from w_HEALTH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916614c",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny logistic regression demo on synthetic data\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(n_samples=800, n_features=10, random_state=0)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "clf = LogisticRegression(max_iter=500).fit(Xtr, ytr)\n",
    "print(\"Accuracy:\", accuracy_score(yte, clf.predict(Xte)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9c5ed",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d0cde",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 4.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Multiclass lecture note](https://www.cs.utexas.edu/~gdurrett/courses/online-course/multiclass.pdf)\n",
    "- [A large annotated corpus for learning natural language inference](https://www.aclweb.org/anthology/D15-1075/)\n",
    "- [Authorship Attribution of Micro-Messages](https://www.aclweb.org/anthology/D13-1193/)\n",
    "- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n",
    "- [[Article] Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)\n",
    "- [[Blog] Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "- [Eisenstein Chapter 3.1-3.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Dropout: a simple way to prevent neural networks from overfitting](https://dl.acm.org/doi/10.5555/2627435.2670313)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
    "- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://papers.nips.cc/paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f12df",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
