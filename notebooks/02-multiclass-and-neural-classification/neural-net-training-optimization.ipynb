{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867ce7d4",
   "metadata": {},
   "source": [
    "# Neural Net Training, Optimization\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/KPZb2rYS4BE](https://youtu.be/KPZb2rYS4BE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae199e6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- What youâ€™ll learn (fill in after watching)\n",
    "- Why it matters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a7656",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- TODO: Summarize the core ideas after viewing the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39589ad",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Train a tiny two-layer neural network on make_moons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-layer neural network on a toy dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_moons(noise=0.2, random_state=0)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16, 16), max_iter=500, random_state=0)\n",
    "mlp.fit(X, y)\n",
    "print(\"Accuracy:\", accuracy_score(y, mlp.predict(X)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d663e",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a536e",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 4.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Multiclass lecture note](https://www.cs.utexas.edu/~gdurrett/courses/online-course/multiclass.pdf)\n",
    "- [A large annotated corpus for learning natural language inference](https://www.aclweb.org/anthology/D15-1075/)\n",
    "- [Authorship Attribution of Micro-Messages](https://www.aclweb.org/anthology/D13-1193/)\n",
    "- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n",
    "- [[Article] Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)\n",
    "- [[Blog] Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "- [Eisenstein Chapter 3.1-3.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Dropout: a simple way to prevent neural networks from overfitting](https://dl.acm.org/doi/10.5555/2627435.2670313)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
    "- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://papers.nips.cc/paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2a304",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
