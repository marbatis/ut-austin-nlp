{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d63896b",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "- Source: [https://youtu.be/My6GaGhqxdI](https://youtu.be/My6GaGhqxdI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12412a6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- What youâ€™ll learn (fill in after watching)\n",
    "- Why it matters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf6968",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- TODO: Summarize the core ideas after viewing the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2c29d",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny logistic regression demo on synthetic data\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(n_samples=800, n_features=10, random_state=0)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "clf = LogisticRegression(max_iter=500).fit(Xtr, ytr)\n",
    "print(\"Accuracy:\", accuracy_score(yte, clf.predict(Xte)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa107d",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset / example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77acdd",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 4.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Multiclass lecture note](https://www.cs.utexas.edu/~gdurrett/courses/online-course/multiclass.pdf)\n",
    "- [A large annotated corpus for learning natural language inference](https://www.aclweb.org/anthology/D15-1075/)\n",
    "- [Authorship Attribution of Micro-Messages](https://www.aclweb.org/anthology/D13-1193/)\n",
    "- [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n",
    "- [[Article] Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)\n",
    "- [[Blog] Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "- [Eisenstein Chapter 3.1-3.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Dropout: a simple way to prevent neural networks from overfitting](https://dl.acm.org/doi/10.5555/2627435.2670313)\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\n",
    "- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://papers.nips.cc/paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html)\n",
    "\n",
    "*Links only; we do not redistribute PDFs or slides.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
