{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4888ab",
   "metadata": {},
   "source": [
    "# RNNs and their Shortcomings\n",
    "\n",
    "- üì∫ **Video:** [https://youtu.be/xvnnA04JVQo](https://youtu.be/xvnnA04JVQo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca5578",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Examines the capabilities and limitations of Recurrent Neural Networks in sequence tasks. The video likely reviews how RNNs work (maybe a simple diagram of an RNN unrolled over time) and then delves into the problem of long-term dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f323ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(0)\n",
    "CI = os.environ.get('CI') == 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319eef0",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- It presents scenarios where an RNN might fail: for instance, trying to capture something far back in a sentence or document (like remembering the subject's number to ensure verb agreement in a long sentence).\n",
    "- The explanation might draw from the classic analysis by Hochreiter and Bengio that vanilla RNNs suffer from vanishing gradients - as we backpropagate through many time steps, gradients either shrink exponentially (vanish) or, less often, blow up, making it hard to learn correlations over long distances The video might use a concrete example: ‚ÄúI grew up in France ‚Ä¶ I speak fluent ___.‚Äù - to correctly predict ‚ÄúFrench‚Äù at the blank, the model must remember ‚ÄúFrance‚Äù from far earlier A simple RNN may struggle with this if the gap is large, as it tends to ‚Äúforget‚Äù earlier content by the time it reaches later words.\n",
    "- This motivates specialized RNN architectures like LSTMs (Long Short-Term Memory) and GRUs (Gated Recurrent Units), which introduce gating mechanisms to help preserve information over long time spans.\n",
    "- The video likely gives an intuition for LSTMs: they have gates that control the flow of information, so they can keep important info in memory (the cell state) for dozens of time steps, essentially addressing the vanishing gradient by design It might show or describe the components of an LSTM (forget gate, input gate, output gate) at a high level, conveying that these gates decide what to keep, write, or output from the memory cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7bbde9",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Try the exercises below and follow the linked materials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea15cf",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26440bb",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 6.1](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Eisenstein 6.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Eisenstein 6.4](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Eisenstein 6.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [[Blog] Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [[Blog] The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation](https://arxiv.org/abs/2108.12409)\n",
    "- [The Impact of Positional Encoding on Length Generalization in Transformers](https://arxiv.org/abs/2305.19466)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de75b6",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
