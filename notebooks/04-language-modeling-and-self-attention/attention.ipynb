{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84003112",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "- ðŸ“º **Video:** [https://youtu.be/q7HY7tpWWi8](https://youtu.be/q7HY7tpWWi8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c6bf3",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Introduce attention as a mechanism for weighted averaging of value vectors using relevance scores.\n",
    "- Understand how attention generalizes alignment ideas from machine translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73443488",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- **Query, key, value:** attention scores keys against the query to weight values.\n",
    "- **Score functions:** dot-product, additive, and scaled dot-product determine focus.\n",
    "- **Context vectors:** weighted sums condition each prediction on relevant inputs.\n",
    "- **Differentiability:** attention weights are learned end-to-end via backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdabaeb",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Calculate attention weights for a toy query-key set and observe how changing queries shifts focus, as illustrated in the lecture (https://youtu.be/sVhHhVgZ72E)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd57c16e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T01:28:40.700227Z",
     "iopub.status.busy": "2025-10-29T01:28:40.700001Z",
     "iopub.status.idle": "2025-10-29T01:28:40.771039Z",
     "shell.execute_reply": "2025-10-29T01:28:40.769521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: [0.44313378 0.32236152 0.2345047 ]\n",
      "Context vector: [0.56038613 0.43961387]\n",
      "\n",
      "With new query:\n",
      "Attention weights: [0.32961847 0.40751098 0.26287054]\n",
      "Context vector: [0.46105375 0.53894625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "queries = np.array([[1.0, 0.5]])\n",
    "keys = np.array([[0.8, 0.6], [0.2, 0.9], [0.0, 0.4]])\n",
    "values = np.array([[1.0, 0.0], [0.0, 1.0], [0.5, 0.5]])\n",
    "\n",
    "scale = np.sqrt(keys.shape[1])\n",
    "logits = queries @ keys.T / scale\n",
    "weights = np.exp(logits - logits.max())\n",
    "weights /= weights.sum()\n",
    "context = weights @ values\n",
    "\n",
    "print('Attention weights:', weights.squeeze())\n",
    "print('Context vector:', context.squeeze())\n",
    "\n",
    "new_query = np.array([[0.1, 1.2]])\n",
    "logits2 = new_query @ keys.T / scale\n",
    "weights2 = np.exp(logits2 - logits2.max())\n",
    "weights2 /= weights2.sum()\n",
    "context2 = weights2 @ values\n",
    "\n",
    "print()\n",
    "print('With new query:')\n",
    "print('Attention weights:', weights2.squeeze())\n",
    "print('Context vector:', context2.squeeze())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818ed32",
   "metadata": {},
   "source": [
    "## Try it\n",
    "- Modify the demo\n",
    "- Add a tiny dataset or counter-example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778a309",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Eisenstein 6.1](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Eisenstein 6.2](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Eisenstein 6.4](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [Eisenstein 6.3](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)\n",
    "- [[Blog] Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [[Blog] The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation](https://arxiv.org/abs/2108.12409)\n",
    "- [The Impact of Positional Encoding on Length Generalization in Transformers](https://arxiv.org/abs/2305.19466)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b0d1f",
   "metadata": {},
   "source": [
    "*Links only; we do not redistribute slides or papers.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
